{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaxYe3bcAgph"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from spacy.matcher import PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMgnGK3fBJa5"
   },
   "outputs": [],
   "source": [
    "#Function to read resumes from the folder one by one\n",
    "mypath='/content/drive/MyDrive/resumes/' #enter your path here where you saved the resumes\n",
    "onlyfiles = [os.path.join(mypath, f) for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "#print(onlyfiles)\n",
    "#function to read resume ends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OocanP7iJVld",
    "outputId": "4f8527cf-e996-4d44-da0a-9b274d6c419d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tika\n",
      "  Downloading https://files.pythonhosted.org/packages/96/07/244fbb9c74c0de8a3745cc9f3f496077a29f6418c7cbd90d68fd799574cb/tika-1.24.tar.gz\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tika) (57.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from tika) (2.23.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->tika) (3.0.4)\n",
      "Building wheels for collected packages: tika\n",
      "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tika: filename=tika-1.24-cp37-none-any.whl size=32894 sha256=85a42b33cba1e5576d79b24ddbe5f974280c4f2526f1b439c8965501fc9430a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/73/9c/f5/0b1b738442fc2a2862bef95b908b374f8e80215550fb2a8975\n",
      "Successfully built tika\n",
      "Installing collected packages: tika\n",
      "Successfully installed tika-1.24\n"
     ]
    }
   ],
   "source": [
    "!pip install tika"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fMF_Tt9CipJn"
   },
   "outputs": [],
   "source": [
    "from tika import parser\n",
    "raw = parser.from_file(\"/content/drive/MyDrive/CVAnalysisFileresponses/RESUMEFileresponses/snehajindal_resume.pdf\")\n",
    "text = raw['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "fsNMg5Lai5q3",
    "outputId": "52fd95e7-a0f2-4f3a-fbfb-a1ae83830583"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSNEHA JINDAL  \\nMECHANICAL ENGINEERING B.E. Undergraduate\\n\\nsneha.jindalmbm@gmail.com\\n\\n7007692490\\n\\n11-08-1999\\n\\nEDUCATION\\n\\nB.E., M.B.M Engineering College 2017 â€“ 2021\\nCGPA- 7.60 (Jai Narain Vyas University)\\n\\nSenior Secondary, Subodh Public School 2016\\n Percentage-80.8% (CBSE Board)\\n\\nHigher Secondary, S.G.N.D.Sikh Academy 2014\\nPercentage-83.6%(CBSE Board)\\n\\nINTERNSHIP\\n\\nRecently done internship from IIT Delhi in the era of \"Centre For Automotive Research And Tribology\"(CART).\\n\\nCompleted six weeks online training on \"Solidworks\" from Internshala.\\n\\nCompleted Second year internship from IIT BHU in the field of \"Enhancing the mechanical properties of carbon steel \\nthrough heat treatment\".\\n\\nSKILLS\\n\\nSolidworks\\n\\nAutocad\\n\\nCreo\\n\\nAnsys\\n\\nACHIEVEMENTS\\n\\nAwarded \"C  Certificate\" from NCC.\\n\\nSecured Third Position in \"TAMASHA\" in BLITZSCHILAG at MNIT Jaipur.\\n\\nWon the First Prize of Best Skit Performance held in college.\\n\\nExperience of National Rock Climbing and Training Camp held at SRINAGAR(UK).\\n\\nGot MERIT CERTIFICATE in digital wellness online challenge.\\n\\nEXTRA CURRICULAR AND PARTICIPATIONS\\n\\nParticipated in CDQ organized by IIT BHU .\\n\\nNCC CADET of 1 Raj Engineering Regt. Jodhpur.\\n\\nParticipated in AAGAAZ (street play) in Mood Indigo at IIT BOMBAY.\\n\\nMember of Drama Club of college and participated in various competitions in different colleges.\\n\\nParticipated in Manthan 18, An international street play festival.\\n\\nAttended Hovercraft workshop at MBM Engineering College.\\n\\nParticipated in C.A.T.C at Jodhpur and Mandar (Sirohi).\\n\\nINTERESTS\\n\\nPlaying Badminton Travelling and Exploring places\\n\\nmailto:sneha.jindalmbm@gmail.com\\ntel:7007692490\\n\\n'"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StU71dK8JUSY"
   },
   "outputs": [],
   "source": [
    "from tika import parser # pip install tika\n",
    "i=0\n",
    "textList = []\n",
    "while i < len(onlyfiles):\n",
    "  raw = parser.from_file(onlyfiles[i])\n",
    "  t = raw['content']\n",
    "  textList.append(t)\n",
    "  i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9QKeipwvgMn"
   },
   "outputs": [],
   "source": [
    "\n",
    "text = ' '.join([str(elem) for elem in textList])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OGWG-QzToIe"
   },
   "outputs": [],
   "source": [
    "#function that does phrase matching and builds a candidate profile\n",
    "def create_profile(file):\n",
    "  #below is the csv where we have all the keywords, you can customize your own\n",
    "  keyword_dict = pd.read_csv('/content/skills_classify.csv',encoding='latin1')\n",
    "  language = [nlp(text) for text in keyword_dict['Languages'].dropna(axis = 0)]\n",
    "  big_data = [nlp(text) for text in keyword_dict['BigDataAnalysis '].dropna(axis = 0)]\n",
    "  coding = [nlp(text) for text in keyword_dict['CodingAndProgramming '].dropna(axis = 0)]\n",
    "  data_science = [nlp(text) for text in keyword_dict['DataScience'].dropna(axis = 0)]\n",
    "  devops = [nlp(text) for text in keyword_dict['DevOps'].dropna(axis = 0)]\n",
    "  cloud = [nlp(text) for text in keyword_dict['CloudComputing'].dropna(axis = 0)]\n",
    "  ops = [nlp(text) for text in keyword_dict['OperatingSystem'].dropna(axis = 0)]\n",
    "  web = [nlp(text) for text in keyword_dict['WebDevelopement'].dropna(axis = 0)]\n",
    "  dbms = [nlp(text) for text in keyword_dict['DBMS'].dropna(axis = 0)]\n",
    "  app = [nlp(text) for text in keyword_dict['AppDevelopment'].dropna(axis = 0)]\n",
    "  security = [nlp(text) for text in keyword_dict['Security'].dropna(axis = 0)]\n",
    "  other = [nlp(text) for text in keyword_dict['Others'].dropna(axis = 0)]\n",
    "\n",
    "  matcher = PhraseMatcher(nlp.vocab)\n",
    "  matcher.add('language', None, *language)\n",
    "  matcher.add('bigData', None, *big_data)\n",
    "  matcher.add('code', None, *coding)\n",
    "  matcher.add('DS', None, *data_science)\n",
    "  matcher.add('devOps', None, *devops)\n",
    "  matcher.add('cloud', None, *cloud)\n",
    "  matcher.add('os', None, *ops)\n",
    "  matcher.add('web', None, *web)\n",
    "  matcher.add('dbms', None, *dbms)\n",
    "  matcher.add('app', None, *app)\n",
    "  matcher.add('security', None, *security)\n",
    "  matcher.add('other', None, *other)\n",
    "  doc = nlp(text)\n",
    "  #print(doc)\n",
    "\n",
    "  \n",
    "  d = []  \n",
    "  matches = matcher(doc)\n",
    "  for match_id, start, end in matches:\n",
    "      rule_id = nlp.vocab.strings[match_id]  # get the unicode ID, i.e. 'COLOR'\n",
    "      span = doc[start : end]  # get the matched slice of the doc\n",
    "      d.append((rule_id, span.text))      \n",
    "  keywords = \"\\n\".join(f'{i[0]} {i[1]} ({j})' for i,j in Counter(d).items())\n",
    "\n",
    "\n",
    "  ## convertimg string of keywords to dataframe\n",
    "  \n",
    "  df = pd.read_csv(StringIO(keywords),names = ['Keywords_List'])\n",
    "  df1 = pd.DataFrame(df.Keywords_List.str.split(' ',1).tolist(),columns = ['Subject','Keyword'])\n",
    "  df2 = pd.DataFrame(df1.Keyword.str.split('(',1).tolist(),columns = ['Keyword', 'Count'])\n",
    "  df3 = pd.concat([df1['Subject'],df2['Keyword'], df2['Count']], axis =1) \n",
    "  df3['Count'] = df3['Count'].apply(lambda x: x.rstrip(\")\"))\n",
    "  #print(df3['Count'].head())\n",
    "\n",
    "  \n",
    "  base = os.path.basename(file)\n",
    "  filename = os.path.splitext(base)[0]\n",
    "     \n",
    "  name = filename.split('_')\n",
    "  name2 = name[0]\n",
    "  name2 = name2.lower()\n",
    "  ## converting str to dataframe\n",
    "  name3 = pd.read_csv(StringIO(name2),names = ['Candidate Name'])\n",
    "  \n",
    "  dataf = pd.concat([name3['Candidate Name'], df3['Subject'], df3['Keyword'], df3['Count']], axis = 1)\n",
    "  dataf['Candidate Name'].fillna(dataf['Candidate Name'].iloc[0], inplace = True)\n",
    "\n",
    "  return(dataf)\n",
    " \n",
    "#function ends\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FMZz3y-jCKi"
   },
   "outputs": [],
   "source": [
    "final_database=pd.DataFrame()\n",
    "dat = create_profile(\"/content/drive/MyDrive/CVAnalysisFileresponses/RESUMEFileresponses/snehajindal_resume.pdf\")\n",
    "final_database = final_database.append(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DU48pQMKfhV2"
   },
   "outputs": [],
   "source": [
    "#code to execute/call the above functions\n",
    "\n",
    "final_database=pd.DataFrame()\n",
    "i = 0 \n",
    "while i < len(onlyfiles):\n",
    "    file = onlyfiles[i]\n",
    "    dat = create_profile(file)\n",
    "    final_database = final_database.append(dat)\n",
    "    i +=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "fQChTYq3fm3O",
    "outputId": "d5b18422-63d0-4a94-a81f-ecd91b107085"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Name</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snehajindal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Candidate Name Subject Keyword Count\n",
       "0    snehajindal     NaN     NaN   NaN"
      ]
     },
     "execution_count": 210,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mTGfz0xIHK-d"
   },
   "outputs": [],
   "source": [
    "#code to count words under each category and visulaize it through Matplotlib\n",
    "\n",
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "sample2=new_data.to_csv('/content/FinalResume_classify.csv')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 10})\n",
    "ax = new_data.plot.barh(title=\"Resume keywords by category\", legend=False, figsize=(25,7), stacked=True)\n",
    "labels = []\n",
    "for j in new_data.columns:\n",
    "    for i in new_data.index:\n",
    "        label = str(j)+\": \" + str(new_data.loc[i][j])\n",
    "        labels.append(label)\n",
    "patches = ax.patches\n",
    "for label, rect in zip(labels, patches):\n",
    "    width = rect.get_width()\n",
    "    if width > 0:\n",
    "        x = rect.get_x()\n",
    "        y = rect.get_y()\n",
    "        height = rect.get_height()\n",
    "        ax.text(x + width/2., y + height/2., label, ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ybWUY4v0cReC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/FinalResume_classify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhaXMzr_ciBP"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV1Fu2fEcjNc",
    "outputId": "59515754-27a8-4091-8262-595535db561b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject         cloud  language  other  web\n",
      "Candidate Name                             \n",
      "yogitatak           1         1      2    2\n"
     ]
    }
   ],
   "source": [
    "final_database2 = final_database['Keyword'].groupby([final_database['Candidate Name'], final_database['Subject']]).count().unstack()\n",
    "print(final_database2)\n",
    "final_database2.reset_index(inplace = True)\n",
    "final_database2.fillna(0,inplace=True)\n",
    "new_data = final_database2.iloc[:,1:]\n",
    "new_data.index = final_database2['Candidate Name']\n",
    "#execute the below line if you want to see the candidate profile in a csv format\n",
    "sample2=new_data.to_csv('/content/FinalResume_classify.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HdF1RwDcjv07"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/FinalResume_classify.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "bdrOCMt0jzIK",
    "outputId": "ddd340c2-f863-487f-d8b3-bae229bd7abe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Candidate Name</th>\n",
       "      <th>bigData</th>\n",
       "      <th>code</th>\n",
       "      <th>language</th>\n",
       "      <th>os</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nitish</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Candidate Name  bigData  code  language  os  web\n",
       "0         nitish        1     1         2   2    2"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkI1d3I3j8l2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "skill_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
